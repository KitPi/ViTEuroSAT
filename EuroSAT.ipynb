{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73ce090-da26-4ad2-8ac0-707f0c33eeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/anaconda3/envs/tf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "535ec665-1336-49eb-95a6-969902feefae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/========== PATHS and VARIABLES ==========\n",
    "model_id = \"google/vit-base-patch16-224-in21k\"\n",
    "dataset_folder = \"EuroSAT/2750\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa368f3-3122-42b0-9ca4-5554a4323f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/========== DATASET ==========\n",
    "import createDataset\n",
    "import datasets\n",
    "import os\n",
    "import PIL\n",
    "\n",
    "dataset = createDataset.create_image_folder_dataset(dataset_folder)\n",
    "img_class_labels = dataset.features[\"label\"].names\n",
    "\n",
    "def create_image_folder_dataset(root_path):\n",
    "    ## list directories\n",
    "    _CLASS_NAMES = os.listdir(root_path)\n",
    "    ## enumerate features\n",
    "    features=datasets.Features({\n",
    "        \"img\": datasets.Image(),\n",
    "        \"label\": datasets.features.ClassLabel(names=_CLASS_NAMES),\n",
    "    })\n",
    "    ## create/populate list of datapoints\n",
    "    img_data_files=[]\n",
    "    label_data_files=[]\n",
    "    for img_class in os.listdir(root_path):\n",
    "        for img in os.listdir(os.path.join(root_path, img_class)):\n",
    "            path_ = os.path.join(root_path, img_class, img)\n",
    "            img_data_files.append(path_)\n",
    "            label_data_files.append(img_class)\n",
    "    ## create dataset\n",
    "    return datasets.Dataset.from_dict({\"img\":img_data_files, \"label\":label_data_files}, features=features)\n",
    "\n",
    "## Make eurosat dataset\n",
    "eurosat_ds = create_image_folder_dataset(\"EuroSAT/2750\")\n",
    "img_class_labels = eurosat_ds.features[\"label\"].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9e6bd60-71c8-4a9e-8449-bbb9a3521e8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 16:48:57.431037: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-11 16:48:57.451485: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 16:48:59.080049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13898 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "Map: 100%|████████████████| 27000/27000 [00:40<00:00, 669.40 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "#/========== PREPROCESSING ==========\n",
    "from transformers import ViTImageProcessor\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "#feature_extractor = ViTFeatureExtractor.from_pretrained(model_id)\n",
    "image_processor = ViTImageProcessor.from_pretrained(model_id)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.Resizing(image_processor.size, image_processor.size),\n",
    "        layers.Rescaling(1./255),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Use keras to augment the image data: apply random transforms to the data to allow the model to generalise better.\n",
    "def augmentation(examples):\n",
    "    examples[\"pixel_values\"] = [data_augmentation(image) for image in examples[\"img\"]]\n",
    "    return examples\n",
    "\n",
    "# Basic image processing\n",
    "def process(examples):\n",
    "    examples.update(image_processor(examples['img'], ))\n",
    "    return examples\n",
    "\n",
    "## Process the dataset\n",
    "processed_dataset = eurosat_ds.map(process, batched=True)\n",
    "processed_dataset\n",
    "\n",
    "## create test dataset \n",
    "# test size will be 30% of train dataset\n",
    "test_size=.3\n",
    "processed_dataset = processed_dataset.shuffle().train_test_split(test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe3fb9a-c01e-4688-8561-6441a1a38bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/========== FINETUNING ==========\n",
    "from huggingface_hub import HfFolder\n",
    "import tensorflow as tf\n",
    "\n",
    "id2label = {str(i): label for i, label in enumerate(img_class_labels)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "# set hyperparameters\n",
    "num_train_epochs = 5\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 32\n",
    "learning_rate = 3e-5\n",
    "weight_decay_rate = 0.01\n",
    "num_warmup_steps = 0\n",
    "output_dir=model_id.split(\"/\")[1]\n",
    "hub_token = HfFolder.get_token()\n",
    "hub_model_id = f'{model_id.split(\"/\")[1]}-euroSat'\n",
    "fp16=True\n",
    "# when training on floating-point 16 set GPU policy to accomodate floating points\n",
    "if fp16:\n",
    "    tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c51c944d-1df3-4c9a-97c5-89f05aab2358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/anaconda3/envs/tf/lib/python3.12/site-packages/datasets/arrow_dataset.py:410: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#/=========== Convert dataset to Tensorflow dataset ===========\n",
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "\n",
    "# convert train dataset to tf.data.Dataset\n",
    "tf_train_dataset = processed_dataset[\"train\"].to_tf_dataset(\n",
    "    columns=[\"pixel_values\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=train_batch_size,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "# convert test dataset to tf.data.Dataset\n",
    "tf_eval_dataset = processed_dataset[\"test\"].to_tf_dataset(\n",
    "    columns=[\"pixel_values\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=train_batch_size,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "941c5065-f340-479a-814f-47d9dbd71ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing TFViTForImageClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFViTForImageClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFViTForImageClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kit/anaconda3/envs/tf/lib/python3.12/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.2/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#/========== Prepare the MODEL ==========\n",
    "from transformers import TFViTForImageClassification, create_optimizer\n",
    "from datasets import load_metric\n",
    "import tensorflow as tf\n",
    " \n",
    "# create optimizer wight weigh decay\n",
    "num_train_steps = len(tf_train_dataset) * num_train_epochs\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=weight_decay_rate,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    ")\n",
    " \n",
    "# load pre-trained ViT model\n",
    "model = TFViTForImageClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(img_class_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    " \n",
    "# define loss\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    " \n",
    "# define metrics\n",
    "#metrics=[\n",
    "#    keras.metrics.SparseCategoricalAccuracy(),\n",
    "#    keras.metrics.SparseTopKCategoricalAccuracy(k=3, name=\"top-3-accuracy\"),\n",
    "#]\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    " \n",
    "# compile model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=['accuracy'],\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cd3acf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1718150153.628602   15899 asm_compiler.cc:252] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "W0000 00:00:1718150153.628626   15899 asm_compiler.cc:255] Used ptxas at /usr/bin/ptxas\n",
      "2024-06-11 16:55:53.628666: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.628681: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.628689: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.628696: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.628703: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.628710: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.628718: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.628727: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.756655: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-06-11 16:55:53.762876: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.762894: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.763358: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.763536: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.763716: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.764034: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.764604: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.765715: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.857024: W external/local_xla/xla/stream_executor/gpu/redzone_allocator.cc:321] UNIMPLEMENTED: /usr/bin/ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-06-11 16:55:53.978799: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.978813: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.978910: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.979305: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.980071: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.980088: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.980380: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:53.980700: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:54.069585: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:54.137575: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:54.320739: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/591 [..............................] - ETA: 2:27:51 - loss: 2.3230 - accuracy: 0.0312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 16:55:54.349923: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:54.371183: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-06-11 16:55:54.390196: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 217s 343ms/step - loss: 0.5357 - accuracy: 0.9420 - val_loss: 0.2075 - val_accuracy: 0.9695\n",
      "Epoch 2/5\n",
      "591/591 [==============================] - 202s 342ms/step - loss: 0.1234 - accuracy: 0.9869 - val_loss: 0.1286 - val_accuracy: 0.9772\n",
      "Epoch 3/5\n",
      "591/591 [==============================] - 202s 342ms/step - loss: 0.0652 - accuracy: 0.9930 - val_loss: 0.0791 - val_accuracy: 0.9856\n",
      "Epoch 4/5\n",
      "591/591 [==============================] - 202s 342ms/step - loss: 0.0391 - accuracy: 0.9973 - val_loss: 0.0665 - val_accuracy: 0.9877\n",
      "Epoch 5/5\n",
      "591/591 [==============================] - 202s 342ms/step - loss: 0.0286 - accuracy: 0.9990 - val_loss: 0.0601 - val_accuracy: 0.9893\n"
     ]
    }
   ],
   "source": [
    "#/========== FIT MODEL ==========\n",
    "train_results = model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_eval_dataset,\n",
    "    #callbacks=callbacks,\n",
    "    epochs=num_train_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ac1a599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/anaconda3/envs/tf/lib/python3.12/site-packages/transformers/generation/tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#/========== SAVE MODEL ==========\n",
    "model.save(\"euroSAT.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a519e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 58s 227ms/step - loss: 0.0601 - accuracy: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.060085661709308624, 0.9892592430114746]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#/========== EVALUATE MODEL ==========\n",
    "model.evaluate(tf_eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac074af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 58s 219ms/step\n"
     ]
    }
   ],
   "source": [
    "#/========== Predict label ==========\n",
    "probs = model.predict(tf_eval_dataset)\n",
    "#classes = keras.np_utils.probas_to_classes(probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
